{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local python tests\n",
    "from pprint import pprint\n",
    "from igraph import *\n",
    "import igraph.test\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import collections\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    %%%%%%%%%%%%%%%%%%%%%%%%%%% gcn tests %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    x  feature vectors\n",
    "    tx feature vectors for test (unlabeled)\n",
    "    allx feature vectors for all\n",
    "\n",
    "    y  label vectors       numpy.ndarray\n",
    "    ty test label vectors  numpy.ndarray\n",
    "    ally  test label of all\n",
    "\n",
    "    graph : adjacency matrix (dict of lists)\n",
    "    test.index: node id list for tests?\n",
    "\n",
    "\n",
    "    steps\n",
    "    1) inspect ind.citeseer.x/tx/y/ty/allx/ally/test.index\n",
    "\n",
    "    2) build those files from code\n",
    "\n",
    "    3) call learning algorithm\n",
    "        cd src/notebooks\n",
    "        python gcn_tests_input.py&&  cp ind.* ../gcn/gcn/gcn/data\n",
    "        cd src/gcn/gcn/gcn\n",
    "        python train.py --dataset t1\n",
    "\n",
    "\n",
    "    4) look at embedding result\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def pickleToDisk(myobj, filepath):\n",
    "    pickle.dump(myobj, open(filepath, \"wb\"))\n",
    "\n",
    "\n",
    "def printGraphObject(filepath):\n",
    "\n",
    "\n",
    "    myobject = os.path.basename(filepath)\n",
    "    print(\"\\n\\n*************** \"+myobject+\" ********************\")\n",
    "    y = pickle.load(open(filepath,'rb'))\n",
    "    print(type(y))\n",
    "    if type(y) ==  type([]) or type(y) == type(np.ndarray([])):\n",
    "        \n",
    "        print(len(y))\n",
    "        pprint(y[:min(3,len(y)-1)])\n",
    "    elif type(y) == type({}) or type(y)==type(collections.defaultdict()):\n",
    "        pprint(y.keys()[:min(3,len(y)-1)])\n",
    "        pprint(y[y.keys()[0]])\n",
    "        pprint(y[y.keys()[1]])\n",
    "        pprint(y[y.keys()[20]])\n",
    "        pprint(y[y.keys()[3000]])\n",
    "\n",
    "    else:\n",
    "        \n",
    "        pprint(y.shape)\n",
    "        pprint(y[0,:min(3,y.shape[1]-1)].toarray())\n",
    "        pprint(y[0,0].shape)\n",
    "        pprint(type(y[0,0]))\n",
    "        pprint(y[0,0])\n",
    "\n",
    "def readListFile(filepath):\n",
    "    myobject = os.path.basename(filepath)\n",
    "    print(\"\\n\\n*************** \"+myobject+\" ********************\")\n",
    "    \n",
    "\n",
    "    testInstances =[]\n",
    "    with open(filepath, 'rb') as f:\n",
    "        for line in f.readlines():\n",
    "            testInstances.append(int(line))\n",
    "\n",
    "    pprint(testInstances[:min(3,len(testInstances)-1)])\n",
    "\n",
    "\n",
    "def inspectData():\n",
    "\n",
    "    printGraphObject('../gcn/gcn/gcn/data/ind.citeseer.y')\n",
    "    printGraphObject('../gcn/gcn/gcn/data/ind.citeseer.ty')\n",
    "    printGraphObject('../gcn/gcn/gcn/data/ind.citeseer.x')\n",
    "    printGraphObject('../gcn/gcn/gcn/data/ind.citeseer.tx')\n",
    "    printGraphObject('../gcn/gcn/gcn/data/ind.citeseer.graph')\n",
    "    readListFile('../gcn/gcn/gcn/data/ind.citeseer.test.index')\n",
    "    printGraphObject('../gcn/gcn/gcn/data/ind.citeseer.allx')\n",
    "    printGraphObject('../gcn/gcn/gcn/data/ind.citeseer.ally')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generateData(suffix):\n",
    "    \n",
    "    \n",
    "\n",
    "    #igraph.test.run_tests()\n",
    "\n",
    "    # generation\n",
    "    #g = Graph.Tree(127, 2)\n",
    "    #g = Graph.GRG(100, 0.2)\n",
    "    #g = Graph.Erdos_Renyi(100, 0.2)\n",
    "    #g = Graph.Watts_Strogatz(1, 100, 4, 0.5 )\n",
    "    n_node = 1700\n",
    "    g = Graph.Barabasi(n_node)\n",
    "    summary(g)\n",
    "\n",
    "    # graph metrics\n",
    "    # pprint(g.degree([2,3,6,99]))\n",
    "    # pprint(g.edge_betweenness())\n",
    "    # pprint(g.pagerank())\n",
    "    #pprint(g.get_adjacency())\n",
    "    #pprint(dir(g))\n",
    "    \n",
    "\n",
    "\n",
    "    # test.index\n",
    "    # list first 5 nodes -> to test.index\n",
    "    n_train = 100\n",
    "    n_test = 300\n",
    "    testList = range(n_node-n_test, n_node)\n",
    "    with open(suffix+'.test.index','wb') as f:\n",
    "        for i in testList:\n",
    "            f.write(str(i)+\"\\n\")\n",
    "\n",
    "    # adjacency dict (graph)\n",
    "    i = 0\n",
    "    A = g.get_adjlist()\n",
    "    graphAdj = {}\n",
    "    for node in A:\n",
    "        graphAdj[i] = node\n",
    "        i+=1\n",
    "    pickleToDisk(graphAdj, suffix+\".graph\")\n",
    "\n",
    "    # features (allx, x, tx)\n",
    "    #  no features -> a 0 for each node \n",
    "    #   or node degree\n",
    "    #  into a sparce matrix\n",
    "    xFeatures = g.degree()\n",
    "    #xFeatures = [feature * 1.0 for feature in xFeatures]\n",
    "    xFeatures = np.array(xFeatures, np.float64)\n",
    "    print(xFeatures[:10])\n",
    "    # see if any degree is negative\n",
    "    degs = np.array(xFeatures)\n",
    "    degs2 = degs < 0\n",
    "    degs3 = degs2.sum(axis=0)\n",
    "    print(degs3)\n",
    "    allx = copy.deepcopy(xFeatures[range(n_node-n_test)])\n",
    "    x = copy.deepcopy(xFeatures[range(n_train)])\n",
    "    #tx = copy.deepcopy(xFeatures[range(n_node-n_test, n_node)])\n",
    "    tx = [xFeatures[i] for i in testList]\n",
    "\n",
    "    \"\"\"\n",
    "    # remove test List\n",
    "    # remove also validation\n",
    "    #for elem in tx:\n",
    "    #    x.pop(x.index(elem))\n",
    "    for elindex in testList:\n",
    "        x.pop(elindex)\n",
    "    \n",
    "    validationList = range(testList[-1]+1, testList[-1]+501)\n",
    "    for elindex in validationList:\n",
    "        x.pop(elindex)\n",
    "    \"\"\"\n",
    "    \n",
    "    allx = csr_matrix(allx)\n",
    "    allx = np.transpose(allx)\n",
    "    pickleToDisk(allx, suffix+\".allx\")\n",
    "    x = csr_matrix(x)\n",
    "    x = np.transpose(x)\n",
    "    pickleToDisk(x, suffix+\".x\")\n",
    "    tx = csr_matrix(tx)\n",
    "    tx = np.transpose(tx)\n",
    "    pickleToDisk(tx, suffix+\".tx\")\n",
    "\n",
    "    print(x.shape)\n",
    "    print(tx.shape)\n",
    "    print(allx.shape)\n",
    "    \n",
    "\n",
    "\n",
    "    # labels (ally,y , ty)\n",
    "    prs = g.pagerank()\n",
    "    print(prs[:10])\n",
    "    prs = np.array(prs)\n",
    "    threshold = 0.01\n",
    "    prs = prs >= threshold\n",
    "    prs2 = prs < threshold\n",
    "\n",
    "    prs = np.vstack((prs,prs2)).T\n",
    "    pprint(prs)\n",
    "\n",
    "    prs_all = copy.deepcopy(prs[range(n_node-n_test)])\n",
    "    prs_train = copy.deepcopy(prs[range(n_train)])\n",
    "    prs_test = [prs[i] for i in testList]\n",
    "    #testList.extend(validationList)\n",
    "    #finalList = testList\n",
    "    #prs_train = [ prs[i] for i in range(prs.shape[0]) if i not in finalList ]\n",
    "\n",
    "    ally = np.array(prs_all)\n",
    "    y = np.array(prs_train)  \n",
    "    ty = np.array(prs_test)\n",
    "\n",
    "\n",
    "    pickleToDisk(ally, suffix+\".ally\")\n",
    "    pickleToDisk(y, suffix+\".y\")\n",
    "    pickleToDisk(ty, suffix+\".ty\")\n",
    "    \n",
    "    print(y.shape)\n",
    "    print(ty.shape)\n",
    "    print(ally.shape)\n",
    "    \n",
    "    \n",
    "\n",
    "    # run training on those files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH U--- 1700 1699 -- \n",
      "[106.   1.   1.  29.  56.  21.   1.  12.  17.   2.]\n",
      "0\n",
      "(100, 1)\n",
      "(300, 1)\n",
      "(1400, 1)\n",
      "[0.02608542064890646, 0.00029741083705712155, 0.00029741083705712155, 0.007147725922553707, 0.013851332276579196, 0.005114423116241617, 0.00029524765834657674, 0.0030641172827451124, 0.004225016638849887, 0.0005847025134382265]\n",
      "array([[ True, False],\n",
      "       [False,  True],\n",
      "       [False,  True],\n",
      "       ...,\n",
      "       [False,  True],\n",
      "       [False,  True],\n",
      "       [False,  True]])\n",
      "(100, 2)\n",
      "(300, 2)\n",
      "(1400, 2)\n"
     ]
    }
   ],
   "source": [
    "generateData(\"ind.t2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csnProjPy2",
   "language": "python",
   "name": "csnprojpy2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
